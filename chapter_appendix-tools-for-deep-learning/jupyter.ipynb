{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install findspark"
      ],
      "metadata": {
        "id": "BzlVjs9U5mj8",
        "outputId": "7476dfa9-56c9-4fcd-e738-7ca015ed918e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BzlVjs9U5mj8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from pyspark.sql.functions import when, col\n",
        "from bs4 import BeautifulSoup\n",
        "import bs4\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "import streamlit as st\n",
        "import requests\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import findspark\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "color_pal = sns.color_palette()\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "\n",
        "\n",
        "session = requests.session()\n",
        "\n",
        "head = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "\n",
        "def get_id(name):\n",
        "    search_url = 'https://www.nseindia.com/api/search/autocomplete?q={}'\n",
        "    get_details = 'https://www.nseindia.com/api/quote-equity?symbol={}'\n",
        "\n",
        "    session.get('https://www.nseindia.com/', headers=head)\n",
        "\n",
        "\n",
        "    search_results = session.get(url=search_url.format(name), headers=head)\n",
        "    search_data = search_results.json()\n",
        "\n",
        "    if 'symbols' in search_data and search_data['symbols']:\n",
        "        search_result = search_data['symbols'][0]['symbol']\n",
        "\n",
        "        company_details = session.get(\n",
        "            url=get_details.format(search_result), headers=head)\n",
        "\n",
        "        try:\n",
        "            identifier = company_details.json()['info']['identifier']\n",
        "            return identifier\n",
        "        except KeyError:\n",
        "            return f\"Identifier not found for '{name}'\"\n",
        "    else:\n",
        "        return f\"No results found for '{name}'\"\n",
        "\n",
        "def read_stock_data(directory):\n",
        "    stock_data = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            stock_name = os.path.splitext(filename)[0]\n",
        "            df = pd.read_csv(os.path.join(directory, filename))\n",
        "            if 'datetime' in df.columns and 'close' in df.columns:\n",
        "                stock_data[stock_name] = df[['datetime', 'close']]\n",
        "    return stock_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Read stock data from archive folder\n",
        "archive_folder = \"archive\"\n",
        "stock_data = read_stock_data(archive_folder)\n",
        "\n",
        "\n",
        "print(stock_data)\n",
        "\n",
        "\n",
        "# Select a stock for visualization\n",
        "selected_stock = input(\"Select a stock: \").upper()\n",
        "\n",
        "# Display historical stock price data\n",
        "print(\"Historical Stock Price Data\")\n",
        "print(selected_stock)\n",
        "print(stock_data[selected_stock])\n",
        "\n",
        "# Plot historical stock prices\n",
        "if selected_stock in stock_data:\n",
        "    df = stock_data[selected_stock]\n",
        "    df['Date'] = pd.to_datetime(df['datetime'])\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df['Date'], df['close'])\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Closing Price\")\n",
        "    plt.title(f\"{selected_stock} Historical Stock Prices\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def find_best_random_state(stock_data, selected_stock):\n",
        "    best_random_state = float('inf')\n",
        "    best_mae = float('inf')\n",
        "    best_r2 = float('-inf')\n",
        "    best_score = float('inf')\n",
        "\n",
        "    if selected_stock in stock_data:\n",
        "        df = stock_data[selected_stock]\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        df['year'] = df['datetime'].dt.year\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        df['day'] = df['datetime'].dt.day\n",
        "\n",
        "        X = df[['year', 'month', 'day']].values\n",
        "        y = df['close']\n",
        "\n",
        "        for random_state in range(1, 1001):\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "            model = XGBRegressor(random_state=random_state)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "            score = mean_squared_error(y_test, y_pred)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "            if score < best_score and mae < best_mae:\n",
        "                best_score = score\n",
        "                best_mae = mae\n",
        "                best_r2 = r2\n",
        "                best_random_state = random_state\n",
        "\n",
        "    return best_random_state, best_score, best_mae, best_r2\n",
        "\n",
        "best_random_state, best_score, best_mae, best_r2 = find_best_random_state(stock_data, selected_stock)\n",
        "print(f\"Best random state: {best_random_state}\")\n",
        "print(f\"Best mse: {best_score}\")\n",
        "print(f\"Best rmse: {np.sqrt(best_score)}\")\n",
        "print(f\"Best mae: {best_mae}\")\n",
        "print(f\"Best r2: {best_r2}\")\n",
        "\n",
        "\n",
        "def selected_train_model(stock_data, selected_stock):\n",
        "    models = {}\n",
        "\n",
        "    # Check if the selected stock is in the stock_data\n",
        "    if selected_stock in stock_data:\n",
        "        df = stock_data[selected_stock]\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        df['year'] = df['datetime'].dt.year\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        df['day'] = df['datetime'].dt.day\n",
        "\n",
        "        X = df[['year', 'month', 'day']].values\n",
        "        y = df['close']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=best_random_state)\n",
        "\n",
        "        model = XGBRegressor(random_state=best_random_state)\n",
        "        model.fit(X_train, y_train)\n",
        "        models[selected_stock] = model\n",
        "    else:\n",
        "        print(f\"Error: {selected_stock} is not in the stock_data\")\n",
        "\n",
        "    return models\n",
        "\n",
        "models = selected_train_model(stock_data, selected_stock)\n",
        "\n",
        "\n",
        "def predict_price(model, date):\n",
        "    # Convert the date to a pandas datetime object\n",
        "    date = pd.to_datetime(date)\n",
        "\n",
        "    # Extract year, month, and day from the date\n",
        "    year = date.year\n",
        "    month = date.month\n",
        "    day = date.day\n",
        "\n",
        "    # Make prediction using the model\n",
        "    prediction = model.predict(np.array([[year, month, day]]))[0]\n",
        "    return prediction\n",
        "\n",
        "\n",
        "today_date = datetime.date.today()\n",
        "if selected_stock in models:\n",
        "    prediction = predict_price(models[selected_stock], today_date)\n",
        "    print(f\"Predicted closing price for {selected_stock} on {today_date}: {prediction}\")\n",
        "else:\n",
        "    print(f\"Model for {selected_stock} is not available.\")\n",
        "\n",
        "\n",
        "company_name = selected_stock\n",
        "\n",
        "# Button to trigger the API call\n",
        "if company_name:\n",
        "    ticker_symbol = get_id(company_name)\n",
        "    st.write(\n",
        "        f\"The stock identifier for '{company_name}' is: {ticker_symbol}\")\n",
        "\n",
        "stock_url = f'https://www.nseindia.com/api/chart-databyindex?index={ticker_symbol}'\n",
        ""
      ],
      "metadata": {
        "id": "b8VvigPl5RFv",
        "outputId": "52569148-ece2-4929-e9c1-56c70c297041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "id": "b8VvigPl5RFv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'archive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cdf914312aa8>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Read stock data from archive folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0marchive_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"archive\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-cdf914312aa8>\u001b[0m in \u001b[0;36mread_stock_data\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mstock_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "R3K0x32M51hV"
      },
      "id": "R3K0x32M51hV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}